{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/nourghaliaabassi/Downloads/dblp-ref/dblp-ref-0.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = []\n",
    "for i in range(4):\n",
    "    file = open('/Users/nourghaliaabassi/Downloads/dblp-ref/dblp-ref-'+str(i)+'.json') \n",
    "    for line in file:\n",
    "        j_content = json.loads(line)\n",
    "        doc.append(j_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = pd.DataFrame(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing = pd.read_pickle('/Users/nourghaliaabassi/missing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1- (len(doc)-(len(doc)-mdoc['abstract'].count()))/len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>id</th>\n",
       "      <th>references</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530475</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>362865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract  authors  id  references  title  venue  year\n",
       "0    530475        4   0      362865      0      0     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing_val = pd.DataFrame(np.zeros(1,))\n",
    "for elem in doc.columns.values:\n",
    "    num_missing_val[elem] = len(doc)-doc[elem].count()\n",
    "\n",
    "del num_missing_val[0]\n",
    "num_missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc.fillna('',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_references_df = doc.loc[doc['references']== '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_abstracts (dataframe):\n",
    "    for i,elem in enumerate(dataframe[:,'abstract']):\n",
    "        if elem == '':\n",
    "            ee = get_ee_from_title(title)\n",
    "            if ee == '':\n",
    "                abstract = get_abtract_scholarly(doc.loc[i,'title'])\n",
    "            else : \n",
    "                json_loads = define_web_scrapper(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_web_scrapper(url):\n",
    "    if 'ieeexplore.ieee' in url:\n",
    "        return IEEE_json_loads(url)\n",
    "    if 'scan' in url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_host(ee):\n",
    "    doc['host']=\"\"\n",
    "        if (pd.isnull(info_df['ee'][i])): continue\n",
    "        if (len(info_df['ee'][i])==0): continue\n",
    "        try:\n",
    "            response = requests.get(info_df['ee'][i],timeout=10)\n",
    "            info_df['host'][i]=urlparse(response.url).hostname\n",
    "            print('at i = {}, {}'.format(i,urlparse(response.url).hostname))\n",
    "        except requests.exceptions.Timeout: info_df['host'][i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = []\n",
    "file = open(path) \n",
    "for line in file:\n",
    "    j_content = json.loads(line)\n",
    "    doc1.append(j_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = pd.DataFrame(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace NaN values with empty lists\n",
    "doc1['references'].loc[doc1['references'].isnull()] = doc1['references'].loc[doc1['references'].isnull()].apply(lambda x: [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = doc1[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tit = urllib.parse.quote('A Fuzzy Multi Criteria Approach for Evaluating Sustainability Performance of Third – Party Reverse Logistics Providers',safe='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get('http://dblp.org/search/publ/api/?q='+tit+'&format=json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from crossref.restful import Works\n",
    "works = Works()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = works.query(title='COMPARING GNG3D AND QUADRIC ERROR METRICS METHODS TO SIMPLIFY 3D MESHES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_doi_info(doi):\n",
    "    response = works.doi(doi)\n",
    "    if (type (response) == dict ): \n",
    "        return response \n",
    "    else: \n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ISBN (doi_info):\n",
    "    if (type (doi_info) == dict ): \n",
    "        try:\n",
    "            return doi_info['ISBN'] \n",
    "        except KeyError: \n",
    "            return []\n",
    "    else: \n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ISSN (doi_info):\n",
    "    if (type (doi_info) == dict ):\n",
    "        try:\n",
    "            return doi_info['ISSN'] \n",
    "        except KeyError: \n",
    "            return ''\n",
    "    else : \n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_referenced_by(doi_info):\n",
    "    if (type (doi_info) == dict ): \n",
    "        try:\n",
    "            return doi_info['is-referenced-by-count']\n",
    "        except KeyError: \n",
    "            return []\n",
    "    else :\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def references_count(doi_info):\n",
    "    if(type (doi_info) == dict ): \n",
    "        try:\n",
    "            return doi_info['references-count']\n",
    "        except: \n",
    "            try: \n",
    "                return doi_info['reference-count']\n",
    "            except:\n",
    "                return []\n",
    "    else :\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_publisher(doi_info):\n",
    "    if type(doi_info)== dict: \n",
    "        try: \n",
    "            return doi_info['publisher']\n",
    "        except KeyError: \n",
    "            return []\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_publisher_location(doi_info):\n",
    "    if type(doi_info)== dict: \n",
    "        try: \n",
    "            return doi_info['publisher-location']\n",
    "        except KeyError: \n",
    "            return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reference_info(doi_info):\n",
    "    if type(doi_info)== dict: \n",
    "        try: \n",
    "            return doi_info['reference']\n",
    "        except KeyError: \n",
    "            return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_affiliation(doi_info):\n",
    "    affiliations = []\n",
    "    #if doi!='':\n",
    "        #if works.doi_exists(doi):\n",
    "            #try:\n",
    "               # response = works.doi(doi)\n",
    "    if (type (doi_info) == dict) :\n",
    "        authors = doi_info['author']\n",
    "        if type(authors) == dict : \n",
    "            if len (authors['affiliation']):\n",
    "                print(doi)\n",
    "                affiliations.append((authors['given']+' '+authors['family'], authors['affiliation'][0]['name']))\n",
    "        else: \n",
    "            for author in authors:\n",
    "                if len (author['affiliation']):\n",
    "                    affiliations.append((author['given']+' '+author['family'], author['affiliation'][0]['name']))\n",
    "    #except KeyError: \n",
    "        #print('doi with no information {}'.format(doi))\n",
    "        return affiliations\n",
    "    else: \n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_container_title(doi_info):\n",
    "    if type(doi_info)== dict: \n",
    "        try: \n",
    "            return doi_info['container-title']\n",
    "        except KeyError: \n",
    "            return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject(doi_info):\n",
    "    if type(doi_info)== dict: \n",
    "        try: \n",
    "            return doi_info['subject']\n",
    "        except KeyError: \n",
    "            return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_author_affiliation(json_load):\n",
    "    list_names = []\n",
    "    list_affiliation = [] \n",
    "    list_ = json_load['authors']\n",
    "    try : \n",
    "        for elem in list_:\n",
    "            list_names.append((elem['name']))\n",
    "            list_affiliation.append(elem['affiliation'])\n",
    "        return list_names,list_affiliation\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_key_words(json_loads):\n",
    "    list_key_words = []\n",
    "    try: \n",
    "        for elem in json_loads['keywords']:\n",
    "            for word in elem['kwd']: \n",
    "                list_key_words.append(word)\n",
    "        return set(list_key_words)\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cited_by (search_query):\n",
    "    try: \n",
    "        response = next(search_query)\n",
    "        return response.bib['citedby']\n",
    "    except StopIteration:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDoi(json_info):\n",
    "    try:\n",
    "        #get the url\n",
    "        #get the doi from json content\n",
    "        doi = json_info['doi']#.replace('\\'','')     \n",
    "    except KeyError:\n",
    "        doi = ''\n",
    "    except JSONDecodeError:\n",
    "        doi = ''\n",
    "    return doi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IEEE_json_loads(url):\n",
    "    response = requests.get(url)\n",
    "    content = soup(response.content, 'html.parser')\n",
    "    data = content.decode_contents()\n",
    "    m = re.search('global.document.metadata=(.+?)};', data)\n",
    "    dict_url = m.group(0)\n",
    "    try : \n",
    "        abstract = json.loads(dict_url[25:-1])['abstract']\n",
    "    except KeyError:\n",
    "        abstract = json.loads(dict_url[25:-1])\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_springle_abstract(ee):\n",
    "    response = requests.get(ee)\n",
    "    content = soup(response.content,'html.parser')\n",
    "    m = content.find('p',{'class','Para'})\n",
    "    return m.decode_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_arxiv(ee):\n",
    "    response = requests.get(ee)\n",
    "    c = soup(response.content,'html.parser')\n",
    "    return c.find('blockquote', {'class':'abstract mathjax'}).find(\"span\", {'class':'descriptor'}).next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_linkinghub_abstract(link):\n",
    "    response = requests.get(link)\n",
    "    response = soup(requests.get(response.url).content,'html.parser')\n",
    "    link = urllib.parse.unquote(response.find('input',{'id':\"redirectURL\"}).get('value'))\n",
    "    final = soup(requests.get(link).content,'html.parser')\n",
    "    found = final.find('div',{'class':'abstract author'})\n",
    "    return found.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_igi_global_abstract(link):\n",
    "    response = requests.get(link)\n",
    "    c = soup(response.content,'html.parser')\n",
    "    return c.find('span',{'id':'ctl00_ctl00_cphMain_cphSection_lblAbstract'}).text[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = pd.read_pickle('/Users/nourghaliaabassi/Downloads/0-100mille/part0-10000.pkl')\n",
    "for i in range (1,10): \n",
    "    file = file.append(pd.read_pickle('/Users/nourghaliaabassi/Downloads/0-100mille/part'+str(i)+'0000-'+str(i+1)+'0000.pkl'))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this paper, we propose a new system monitoring framework that can serve as an enabler for automated malware detection on live systems. Our approach takes advantage of the increased availability of hardware assisted virtualization capabilities of modern CPUs, and its basic novelty consists in launching a hypervisor layer on the live system without stopping and restarting it. This hypervisor runs at a higher privilege level than the OS itself, thus, it can be used to observe the behavior of the analyzed system in a transparent manner. For this purpose, we also propose a novel system call tracing method that is designed to be configurable in terms of transparency and granularity.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IEEE_json_loads(file.loc[878014,'relink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response= requests.get(file.loc[878014,'relink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = soup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = re.search('global.document.metadata=(.+?)};', c.decode_contents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_url = m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this paper, we propose a new system monitoring framework that can serve as an enabler for automated malware detection on live systems. Our approach takes advantage of the increased availability of hardware assisted virtualization capabilities of modern CPUs, and its basic novelty consists in launching a hypervisor layer on the live system without stopping and restarting it. This hypervisor runs at a higher privilege level than the OS itself, thus, it can be used to observe the behavior of the analyzed system in a transparent manner. For this purpose, we also propose a novel system call tracing method that is designed to be configurable in terms of transparency and granularity.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(dict_url[25:-1])['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      https://link.springer.com/chapter/10.1007/978-...\n",
       "7      https://link.springer.com/chapter/10.1007/978-...\n",
       "9      https://link.springer.com/chapter/10.1007/978-...\n",
       "15     https://link.springer.com/chapter/10.1007/3-54...\n",
       "18     https://link.springer.com/chapter/10.1007/978-...\n",
       "27     https://link.springer.com/chapter/10.1007/978-...\n",
       "28     https://link.springer.com/chapter/10.1007/978-...\n",
       "30     https://link.springer.com/chapter/10.1007/978-...\n",
       "33     https://www.fujipress.jp/jaciii/jc/jacii001100...\n",
       "38     https://link.springer.com/chapter/10.1007/978-...\n",
       "39     https://link.springer.com/chapter/10.1007/978-...\n",
       "40     https://link.springer.com/referenceworkentry/1...\n",
       "41     https://www.degruyter.com/view/j/icom.2004.3.i...\n",
       "42     https://link.springer.com/chapter/10.1007/978-...\n",
       "44     http://linkinghub.elsevier.com/retrieve/pii/07...\n",
       "53     https://link.springer.com/chapter/10.1007/978-...\n",
       "55     http://ieeexplore.ieee.org:80/document/7427699...\n",
       "59     https://link.springer.com/chapter/10.1007/978-...\n",
       "60     https://link.springer.com/chapter/10.1007/978-...\n",
       "63     https://link.springer.com/chapter/10.1007/978-...\n",
       "71     https://link.springer.com/chapter/10.1007/978-...\n",
       "76     https://link.springer.com/chapter/10.1007/978-...\n",
       "77     https://link.springer.com/chapter/10.1007/978-...\n",
       "86     https://link.springer.com/chapter/10.1007/978-...\n",
       "92     https://link.springer.com/chapter/10.1007/978-...\n",
       "93     https://link.springer.com/chapter/10.1007/978-...\n",
       "96     https://link.springer.com/chapter/10.1007/0-38...\n",
       "97     https://link.springer.com/chapter/10.1007/978-...\n",
       "98     https://link.springer.com/chapter/10.1007/978-...\n",
       "99     https://link.springer.com/chapter/10.1007/978-...\n",
       "                             ...                        \n",
       "329    http://epubs.siam.org/doi/abs/10.1137/1.978161...\n",
       "330    https://link.springer.com/chapter/10.1007/978-...\n",
       "333    https://link.springer.com/chapter/10.1007/978-...\n",
       "335    https://link.springer.com/chapter/10.1007/978-...\n",
       "341    https://link.springer.com/chapter/10.1007/978-...\n",
       "344    https://link.springer.com/chapter/10.1007/978-...\n",
       "345    http://linkinghub.elsevier.com/retrieve/pii/S0...\n",
       "346    https://link.springer.com/chapter/10.1007/978-...\n",
       "355    https://link.springer.com/chapter/10.1007/978-...\n",
       "379    https://link.springer.com/chapter/10.1007/0-38...\n",
       "380    https://link.springer.com/chapter/10.1007/978-...\n",
       "382    https://link.springer.com/chapter/10.1007/978-...\n",
       "385    http://www.mitpressjournals.org/doi/10.1162/co...\n",
       "388    https://www.jstage.jst.go.jp/article/transinf/...\n",
       "393    http://www.jucs.org/doi?doi=10.3217/jucs-006-0...\n",
       "394    http://linkinghub.elsevier.com/retrieve/pii/S0...\n",
       "404    https://link.springer.com/chapter/10.1007/BFb0...\n",
       "408    https://link.springer.com/article/10.1023/A:10...\n",
       "412    https://link.springer.com/chapter/10.1007/978-...\n",
       "413          http://ebooks.iospress.nl/publication/21232\n",
       "414    https://link.springer.com/chapter/10.1007/3-54...\n",
       "415    https://link.springer.com/chapter/10.1007/978-...\n",
       "420    http://ieeexplore.ieee.org:80/document/709379/...\n",
       "429    https://link.springer.com/chapter/10.1007/978-...\n",
       "432    https://link.springer.com/chapter/10.1007/BFb0...\n",
       "443    https://link.springer.com/article/10.1007/s104...\n",
       "449    https://link.springer.com/chapter/10.1007/978-...\n",
       "451    https://link.springer.com/chapter/10.1007/978-...\n",
       "456    http://www.jstor.org/stable/10.4169/000298910x...\n",
       "459    https://link.springer.com/chapter/10.1007/3-54...\n",
       "Name: relink, Length: 100, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essaie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap(relink):\n",
    "    abstract = ''\n",
    "    try :\n",
    "        if relink.__contains__('link.springer'):\n",
    "            abstract = get_springle_abstract(relink)\n",
    "        elif relink.__contains__('igi-global'):\n",
    "            abstract = get_igi_global_abstract(relink)\n",
    "        elif relink.__contains__('ieeexplore'): \n",
    "            abstract = IEEE_json_loads(relink)\n",
    "        elif relink.__contains__('get_abstract_arxiv'):\n",
    "            abstract = get_abstract_arxiv(relink)\n",
    "        elif relink.__contains__('linkinghub'):\n",
    "            abstract = get_linkinghub_abstract(relink)\n",
    "    except AttributeError:\n",
    "        abstract = 'error'\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file['abstract'] = file['relink'].apply(scrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abst = essaie.apply(scrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      This paper deals with the efficient management...\n",
       "7      Authentication capability and stego image dist...\n",
       "9      In this paper there is a method of real-time r...\n",
       "15     Evolution (incremental change) of software is ...\n",
       "18     Catastrophic events can result in great loss o...\n",
       "27     A new knowledge-creation model, called sensor-...\n",
       "28     We study the dynamic bin packing problem intro...\n",
       "30     Edge detection is a process usually applied to...\n",
       "33                                                      \n",
       "38     In this article we propose an extension to the...\n",
       "39     The purpose of visualization is to present inf...\n",
       "40     Emerging technologies that enable the engineer...\n",
       "41                                                      \n",
       "42     The ability to monitor the change in expressio...\n",
       "44     An analytic approximation for the blocking pro...\n",
       "53     We believe that there are persuasive arguments...\n",
       "55     This short paper serves to introduce the minit...\n",
       "59     In this paper we introduce two project evoluti...\n",
       "60     Business Models play a pivotal role in organiz...\n",
       "63     We present a new bound relating edge connectiv...\n",
       "71     As logic programming applications grow in size...\n",
       "76     Government services are almost always monopoly...\n",
       "77     Due to demographic changes, European healthcar...\n",
       "86     Mobile devices are more and more integrated in...\n",
       "92     It is a common approach to create and inspect ...\n",
       "93     In 1999, Jerome Solinas introduced families of...\n",
       "96     The Next Steps In Signaling (NSIS) working gro...\n",
       "97     Due to the worldwide diversity of enterprises,...\n",
       "98     Profile-driven personalization based on socio-...\n",
       "99     Das Informationssystem für Umweltchemikalien, ...\n",
       "                             ...                        \n",
       "329                                                     \n",
       "330    The authors propose the incompleteness factor ...\n",
       "333    Stakeholder gehen vermehrt dazu über Informati...\n",
       "335    A new algorithm meant for content based image ...\n",
       "341    The purpose of this study is to find the best ...\n",
       "344    Sharpening is one of basic culinary for a cook...\n",
       "345    It is well known that formally defining and re...\n",
       "346    While performing an evolution task, programmer...\n",
       "355    Efficient applications of expert systems to pr...\n",
       "379    The management of Virtual Organization (VO) br...\n",
       "380    Advances in technology have enabled increasing...\n",
       "382    Pattern detection serves different purposes in...\n",
       "385                                                     \n",
       "388                                                     \n",
       "393                                                     \n",
       "394    errorhttp://linkinghub.elsevier.com/retrieve/p...\n",
       "404    errorhttps://link.springer.com/chapter/10.1007...\n",
       "408    This paper presents a novel networking archite...\n",
       "412    Organ definition in computed tomography (CT) i...\n",
       "413                                                     \n",
       "414    We developed a non-linear registration techniq...\n",
       "415    In order to evaluate traffic operation safety ...\n",
       "420    Cellular automaton (CA) is a promising compute...\n",
       "429    MARVIN ist ein autonom fliegender Beobachtungs...\n",
       "432    In this paper, we consider the representation ...\n",
       "443    We consider planning problems where a number o...\n",
       "449    The pore space type of oolitic shoal reservoir...\n",
       "451    In this paper, the explicit determinants are p...\n",
       "456                                                     \n",
       "459    The paper first summarizes main approaches to ...\n",
       "Name: relink, Length: 100, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://doi.org/10.1109/HPCC-SmartCity-DSS.2016.0121')\n",
    "content = soup(response.text, 'html.parser')\n",
    "data = content.decode_contents()\n",
    "m = re.search('global.document.metadata=(.+?)};', data)\n",
    "dict_url = m.group(0)\n",
    "dict_url = json.loads(dict_url[25:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_key_words(json.loads(dict_url2[25:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_scholarly(title):\n",
    "    search_query = scholarly.search_pubs_query(title)\n",
    "    return print(next(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lis = ['10.1145/3036698','10.1145/303669','10.1007/978-3-642-27180-9_13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#works.doi('10.1145/3036698-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lis_doi = pd.Series(lis).apply(get_doi_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lis_doi.apply(get_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elem in lis_doi.apply(get_reference_info).iloc[0]: \n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_references_list(reference_info):\n",
    "    #if(len(reference_info)>0):\n",
    "        #for elem in reference_info:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "works.doi('10.1007/978-3-642-27180-9_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from crossref.restful import Journals\n",
    "#journals = Journals()\n",
    "#journals.journal('0001-0782')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get('http://dblp.org/search/publ/api/?q=Development of Remote Monitoring and Control Device for 50KW PV System Based on the Wireless Network&format=json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.iloc[46,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['doi'] = test.iloc[:100,4].apply(getDoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = 'COMPARING GNG3D AND QUADRIC ERROR METRICS METHODS TO SIMPLIFY 3D MESHES'\n",
    "response = requests.get(base+title+end)\n",
    "content = json.loads(response.content)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scholarly\n",
    "search_query = scholarly.search_author('Antonio Zamora')\n",
    "print(next(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#auth = next(scholarly.search_author(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get_author_id function \n",
    "base_auth = 'http://dblp.org/search/author/api/?q='\n",
    "end = '&format=json'\n",
    "\n",
    "def get_author_id(title):\n",
    "    ids = []\n",
    "    try:\n",
    "        response = requests.get(base+urllib.parse.quote(title,safe='')+end)\n",
    "        content = json.loads(response.content)\n",
    "        authors = content['result']['hits']['hit'][0]['info']['authors']['author']\n",
    "        typ = type(authors)\n",
    "        if typ == str:\n",
    "            get_res_auth = requests.get(base_auth+urllib.parse.quote(authors,safe='')+end)\n",
    "            get_cont_auth = json.loads(get_res_auth.content)\n",
    "            ids.append((authors, get_cont_auth['result']['hits']['hit'][0]['@id']))\n",
    "        else: \n",
    "            for author in authors:\n",
    "                try:\n",
    "                    get_res_auth = requests.get(base_auth+urllib.parse.quote(author,safe='')+end)\n",
    "                    get_cont_auth = json.loads(get_res_auth.content)\n",
    "                    ids.append((author, get_cont_auth['result']['hits']['hit'][0]['@id']))\n",
    "                except KeyError:\n",
    "                    ids.append((author, 'None'))\n",
    "    except KeyError:\n",
    "        ids.append(('None', 'None'))\n",
    "    return ids\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test['Author_id']=test.iloc[:100,4].apply(get_author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Author_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_papers = list(test['id'][:10000])\n",
    "import networkx as nx \n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(all_papers[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(10000)):\n",
    "        for paper in test['references'][i]:\n",
    "            if paper in all_papers:\n",
    "                G.add_edge(all_papers[i],paper)\n",
    "#plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.axis('off')\n",
    "plt.title('title')\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G,pos,\n",
    "                       node_color='b',\n",
    "                       node_size=100,\n",
    "                   alpha=0.8)\n",
    "nx.draw_networkx_edges(G,pos,alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for paper in test['references'][0]:\n",
    "    print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_rank = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_values = nx.hits_numpy(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_rank_scores = pd.DataFrame.from_dict(page_rank, orient='index')\n",
    "page_rank_scores = page_rank_scores.rename(columns = {0:'scores'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_rank_scores = page_rank_scores.sort_values(by = 'scores',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_rank_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_values = pd.DataFrame.from_dict(auth_values, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_values  = auth_values.rename(columns={0:'scores'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_values = auth_values.sort_values(by='scores',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doi_info = works.doi('10.1145/3036698')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doi_info['author'][0]['affiliation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_container_title(doi_info):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(works.doi('10.1007/978-3-642-27180-9_13')['author'][0]['affiliation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_affiliation(doi_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['affiliation_auth'] = pd.DataFrame(test['doi']).fillna(value = '')['doi'].apply(get_affiliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['affiliation_auth'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = []\n",
    "if not len(seq):\n",
    "    print('salut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part of our data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession\n",
    "import async_timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "springer = pd.read_pickle('springer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treat_springer(content):\n",
    "    m = soup(content,'html.parser').find('p',{'class','Para'})\n",
    "    if m:return m.text\n",
    "    else: return 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async def fetch_all(urls):\n",
    "    \"\"\"Launch requests for all web pages.\"\"\"\n",
    "    tasks = []\n",
    "    async with ClientSession() as session:\n",
    "        for i in range(len(urls)):\n",
    "            task = asyncio.ensure_future(fetch(urls[i], session))\n",
    "            tasks.append(task) # create list of tasks\n",
    "        return await asyncio.gather(*tasks) # gather task responses\n",
    "\n",
    "async def fetch(url,session):\n",
    "    \"\"\"Fetch a url, using specified ClientSession.\"\"\"\n",
    "    with async_timeout.timeout(10):\n",
    "        try: \n",
    "            async with session.get(url) as response:\n",
    "                content = await response.text()\n",
    "            return treat_springer(content)\n",
    "        except asyncio.CancelledError:\n",
    "            return 'timeout'\n",
    "        except aiohttp.ClientOSError:\n",
    "            return 'bad link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(i,step):\n",
    "    loop = asyncio.get_event_loop() # event loop\n",
    "    future = asyncio.ensure_future(fetch_all(springer['ee'].iloc[i:i+step].values)) # tasks to do\n",
    "    responses = loop.run_until_complete(future) # loop until done\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap(start,end):\n",
    "    stack = []\n",
    "    for i in tqdm(np.arange(start,end,20)):\n",
    "        responses= run(i,20)\n",
    "        for j in range(len(responses)):\n",
    "            stack.append(responses[j])\n",
    "    springer['abstract'][start:end] = stack\n",
    "    springer[start:end].to_pickle('part'+str(start)+'-'+str(end)+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final part of our data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('dblp.xml',tag='www',load_dtd=True)\n",
    "\n",
    "for event,elem in context:\n",
    "    elem.getparent().remove(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('dblp.xml',load_dtd=True,tag='mastersthesis')\n",
    "\n",
    "for event, elem in context:\n",
    "    elem.getparent().remove(elem)\n",
    "    \n",
    "ET.ElementTree(context.root).write('output.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output.xml',load_dtd=True,tag='phdthesis')\n",
    "\n",
    "for event, elem in context:\n",
    "    elem.getparent().remove(elem)\n",
    "    \n",
    "ET.ElementTree(context.root).write('output2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output2.xml',load_dtd=True,tag='www')\n",
    "\n",
    "for event, elem in context:\n",
    "    elem.getparent().remove(elem)\n",
    "    \n",
    "ET.ElementTree(context.root).write('output3.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output2.xml',load_dtd=True,tag='article')\n",
    "\n",
    "count = 0\n",
    "for event, elem in context:\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output2.xml',load_dtd=True,tag='inproceedings')\n",
    "\n",
    "count = 0\n",
    "for event, elem in context:\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output2.xml',load_dtd=True,tag='proceedings')\n",
    "\n",
    "count = 0\n",
    "for event, elem in context:\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output2.xml',load_dtd=True,tag='book')\n",
    "\n",
    "count = 0\n",
    "for event, elem in context:\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output2.xml',load_dtd=True,tag='incollection')\n",
    "\n",
    "count = 0\n",
    "for event, elem in context:\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('output.xml',load_dtd=True,tag=('mastersthesis', 'phdthesis','www','book','incollection'))\n",
    "\n",
    "count = 0\n",
    "for event, elem in context:\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('dblp.xml',load_dtd=True,tag='mastersthesis')\n",
    "\n",
    "for event, elem in context:\n",
    "    for child in elem:\n",
    "        if child.tag == 'title':\n",
    "            print(child.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('dblp.xml',load_dtd=True,tag='article')\n",
    "\n",
    "stack = []\n",
    "for event, elem in context:\n",
    "    stack.append({'title':elem.findtext('title'),'year':elem.findtext('year')})\n",
    "    elem.clear()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r'D:\\ADA\\dblp_xml\\inproceedings.pkl', 'rb') as f:\n",
    "    stack = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['title']=\"\"\n",
    "data['year']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truth = []\n",
    "for i in range(len(data)):\n",
    "    if (isinstance(data['author'],list)):\n",
    "        truth.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['children'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['article'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(children,i):\n",
    "    authors=[]\n",
    "    for elem in children:\n",
    "        if list(elem.keys())[0] in ['pages','booktitle','crossref','url']:continue\n",
    "        if list(elem.keys())[0] == 'author':\n",
    "            authors.append(list(elem.values())[0])\n",
    "        if list(elem.keys())[0] == 'title' :\n",
    "            data['title'][i] = list(elem.values())[0]\n",
    "        if list(elem.keys())[0] == 'year':\n",
    "            data['year'][i] = list(elem.values())[0]\n",
    "        if list(elem.keys())[0] == 'ee':\n",
    "            data['ee'][i] = list(elem.values())[0]\n",
    "    data['authors'][i] = authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(children):\n",
    "    d={}\n",
    "    authors=[]\n",
    "    for elem in children:\n",
    "        if list(elem.keys())[0] in ['pages','booktitle','crossref','url']:continue\n",
    "        if list(elem.keys())[0] == 'author':\n",
    "            authors.append(list(elem.values())[0])\n",
    "        if list(elem.keys())[0] == 'title' :d['title']=list(elem.values())[0]\n",
    "        if list(elem.keys())[0] == 'year':d['year']=list(elem.values())[0]\n",
    "        if list(elem.keys())[0] == 'ee':d['ee']=list(elem.values())[0]\n",
    "    d['authors']= authors\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "process(data['children'][0])\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean=[]\n",
    "for i in tqdm(range(len(data))):\n",
    "    clean.append(process(data['children'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df.to_pickle('paper_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['authors']=\"\"\n",
    "data['title']=\"\"\n",
    "data['ee']=\"\"\n",
    "data['year']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "    process(data['children'][i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = {'a':3,'b':5}\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data) # element tree\n",
    "    all_records = [] #This is our record list which we will convert into a dataframe\n",
    "    for i, child in enumerate(root): #Begin looping through our root tree\n",
    "        record = {} #Place holder for our record\n",
    "        for subchild in child: #iterate through the subchildren to user-agent, Ex: ID, String, Description.\n",
    "            record[subchild.tag] = subchild.text #Extract the text create a new dictionary key, value pair\n",
    "            all_records.append(record) #Append this record to all_records.\n",
    "    return pd.DataFrame(all_records) #return records as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ET.iterparse('dblp.xml',load_dtd=True,tag='article')\n",
    "stack=[]\n",
    "for event, elem in context:\n",
    "    stack.append(elem2dict(elem))\n",
    "    elem.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elem2dict(node):\n",
    "    \"\"\"\n",
    "    Convert an lxml.etree node tree into a dict.\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for e in node.iterchildren():\n",
    "        key = e.tag.split('}')[1] if '}' in e.tag else e.tag\n",
    "        value = e.text if e.text else elem2dict(e)\n",
    "        if key in d.keys():\n",
    "            d[key]= list(d[key]).append(value)\n",
    "        d[key]=value\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def xml2d(e):\n",
    "    \"\"\"Convert an etree into a dict structure\n",
    "\n",
    "    @type  e: etree.Element\n",
    "    @param e: the root of the tree\n",
    "    @return: The dictionary representation of the XML tree\n",
    "    \"\"\"\n",
    "    def _xml2d(e):\n",
    "        kids = dict(e.attrib)\n",
    "        if e.text:\n",
    "            kids['__text__'] = e.text\n",
    "        if e.tail:\n",
    "            kids['__tail__'] = e.tail\n",
    "        for k, g in groupby(e, lambda x: x.tag):\n",
    "            g = [ _xml2d(x) for x in g ] \n",
    "            kids[k]=  g\n",
    "        return kids\n",
    "    return { e.tag : _xml2d(e) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_dict(element):\n",
    "    if element.text == None and len(element.attrib):\n",
    "        return element.tag, element.attrib\n",
    "    return element.tag, \\\n",
    "            dict(map(recursive_dict, element)) or element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### tabboura #####\n",
    "def recursive_dict(elem):\n",
    "    retval = {}\n",
    "    if elem.text:\n",
    "        retval[elem.tag] = elem.text\n",
    "\n",
    "    if len(elem) > 0:\n",
    "        retval[\"children\"] = [recursive_dict(child_element) for child_element in elem]\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree, objectify\n",
    "\n",
    "def formatXML(parent):\n",
    "    \"\"\"                                                                                                       \n",
    "    Recursive operation which returns a tree formated                                                         \n",
    "    as dicts and lists.                                                                                       \n",
    "    Decision to add a list is to find the 'List' word                                                         \n",
    "    in the actual parent tag.                                                                                 \n",
    "    \"\"\"\n",
    "    ret = {}\n",
    "    if parent.items(): ret.update(dict(parent.items()))\n",
    "    if parent.text: ret['__content__'] = parent.text\n",
    "    if ('List' in parent.tag):\n",
    "        ret['__list__'] = []\n",
    "        for element in parent:\n",
    "            if element.tag is not etree.Comment:\n",
    "                ret['__list__'].append(formatXML(element))\n",
    "    else:\n",
    "        for element in parent:\n",
    "            if element.tag is not etree.Comment:\n",
    "                ret[element.tag] = formatXML(element)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xmltodict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "context = ET.iterparse('dblp.xml',load_dtd=True,tag='inproceedings')\n",
    "number=0\n",
    "for event, elem in context:\n",
    "    number +=1\n",
    "    elem.clear()\n",
    "    while elem.getprevious() is not None:\n",
    "        del elem.getparent()[0]\n",
    "del context\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "context = ET.iterparse(r'C:\\Users\\User\\Desktop\\dblp\\dblp-2017-12-01.xml',load_dtd=True,tag='article')\n",
    "stack=[]\n",
    "for event, elem in context:\n",
    "    stack.append(recursive_dict(elem))\n",
    "    elem.clear()\n",
    "    while elem.getprevious() is not None:\n",
    "        del elem.getparent()[0]\n",
    "del context\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('inproceedings.pkl', 'wb') as f:\n",
    "    pickle.dump(stack, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
